{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e5ed971b-2eb0-4abe-8404-864f3e4db913",
   "metadata": {},
   "source": [
    "**Import Libraries**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48bfcfc2-ab6e-4eb9-ae99-965389f7ea43",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import requests\n",
    "from PIL import Image\n",
    "from io import BytesIO\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c98ba09c-eeb2-4f3d-8152-d3a99e683607",
   "metadata": {},
   "source": [
    "**Download Images**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04169e03-60bc-44f7-bdcc-8d30e2e5dab3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images downloaded!\n"
     ]
    }
   ],
   "source": [
    "# Directory to save images\n",
    "IMAGE_DIR = 'img/train'\n",
    "\n",
    "# Function to download an image\n",
    "def download_image(url, image_path):\n",
    "    try:\n",
    "        response = requests.get(url, timeout=10)\n",
    "        img = Image.open(BytesIO(response.content))\n",
    "        img.save(image_path)\n",
    "    except Exception as e:\n",
    "        print(f\"Error downloading image from {url}: {e}\")\n",
    "\n",
    "# Read the dataset\n",
    "df = pd.read_csv('dataset/sample_train.csv')\n",
    "\n",
    "# Download the images\n",
    "def download_images(df, IMG_DIR):\n",
    "    # Ensure the image directory exists\n",
    "    if not os.path.exists(IMAGE_DIR):\n",
    "        os.makedirs(IMAGE_DIR)\n",
    "        \n",
    "    for i, row in df.iterrows():\n",
    "        image_url = row['image_link']\n",
    "        image_path = os.path.join(IMG_DIR, f'image_{i}.jpg')\n",
    "        download_image(image_url, image_path)\n",
    "    \n",
    "    print(\"Images downloaded!\")\n",
    "\n",
    "download_images(df, IMAGE_DIR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b99a9741-587a-44da-bf1f-fed8bf39b4c2",
   "metadata": {},
   "source": [
    "**Data Extraction**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bd41829-8209-499f-bf91-7049a04df707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image data shape: (150, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "def preprocess_image(image_path, img_size=(224, 224)):\n",
    "    try:\n",
    "        image = cv2.imread(image_path)\n",
    "        if image is None:\n",
    "            raise ValueError(f\"Failed to load image: {image_path}\")\n",
    "        image = cv2.resize(image, img_size)\n",
    "        image = image / 255.0  # Normalize to [0,1]\n",
    "        return image\n",
    "    except Exception as e:\n",
    "        print(f\"Error preprocessing image {image_path}: {e}\")\n",
    "        return np.zeros((img_size[0], img_size[1], 3))  # Return black image as fallback\n",
    "\n",
    "# Preprocess all images\n",
    "def getData(df, IMG_DIR):    \n",
    "    image_data = []\n",
    "    for i in range(len(df)):\n",
    "        image_path = os.path.join(IMG_DIR, f'image_{i}.jpg')\n",
    "        image = preprocess_image(image_path)\n",
    "        image_data.append(image)\n",
    "\n",
    "    # Convert to numpy array\n",
    "    return np.array(image_data)\n",
    "\n",
    "image_data = getData(df, IMAGE_DIR)\n",
    "print(f\"Image data shape: {image_data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5350e24f-bf7d-4028-b48e-2dbcf9e071c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     entity_value     value       unit\n",
      "0      500.0 gram   500.000       gram\n",
      "1         1.0 cup     1.000        cup\n",
      "2      0.709 gram     0.709       gram\n",
      "3      0.709 gram     0.709       gram\n",
      "4  1400 milligram  1400.000  milligram\n"
     ]
    }
   ],
   "source": [
    "def extract_value_and_unit(entity_value):\n",
    "    if isinstance(entity_value, str):\n",
    "        parts = entity_value.split()\n",
    "        if len(parts) == 2 and parts[0].replace('.', '', 1).isdigit():\n",
    "            return float(parts[0]), parts[1]\n",
    "    return None, None\n",
    "\n",
    "df['value'], df['unit'] = zip(*df['entity_value'].apply(extract_value_and_unit))\n",
    "\n",
    "# Drop rows with missing or invalid values\n",
    "df = df.dropna(subset=['value'])\n",
    "\n",
    "print(df[['entity_value', 'value', 'unit']].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58855801-b5ef-416f-8ab3-88565a605e4a",
   "metadata": {},
   "source": [
    "**Improved CNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d721264a-afd4-4c63-b811-31db77b7b4ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91798\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.12_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python312\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:107: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                         </span>┃<span style=\"font-weight: bold\"> Output Shape                </span>┃<span style=\"font-weight: bold\">         Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">222</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)         │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">111</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │          <span style=\"color: #00af00; text-decoration-color: #00af00\">18,496</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">109</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        │             <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">54</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │          <span style=\"color: #00af00; text-decoration-color: #00af00\">73,856</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">52</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │             <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> │\n",
       "│ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling2D</span>)       │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">26</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">86528</span>)               │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │      <span style=\"color: #00af00; text-decoration-color: #00af00\">11,075,712</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)                    │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)                 │               <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)                  │           <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                      │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)                   │              <span style=\"color: #00af00; text-decoration-color: #00af00\">65</span> │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                        \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape               \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m        Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━┩\n",
       "│ conv2d (\u001b[38;5;33mConv2D\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m896\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization                  │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m222\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │             \u001b[38;5;34m128\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d (\u001b[38;5;33mMaxPooling2D\u001b[0m)         │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m111\u001b[0m, \u001b[38;5;34m32\u001b[0m)        │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_1 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │          \u001b[38;5;34m18,496\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_1                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m109\u001b[0m, \u001b[38;5;34m64\u001b[0m)        │             \u001b[38;5;34m256\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_1 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m54\u001b[0m, \u001b[38;5;34m64\u001b[0m)          │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ conv2d_2 (\u001b[38;5;33mConv2D\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │          \u001b[38;5;34m73,856\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ batch_normalization_2                │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m52\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │             \u001b[38;5;34m512\u001b[0m │\n",
       "│ (\u001b[38;5;33mBatchNormalization\u001b[0m)                 │                             │                 │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ max_pooling2d_2 (\u001b[38;5;33mMaxPooling2D\u001b[0m)       │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m26\u001b[0m, \u001b[38;5;34m128\u001b[0m)         │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m86528\u001b[0m)               │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │      \u001b[38;5;34m11,075,712\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)                    │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)                 │               \u001b[38;5;34m0\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)                  │           \u001b[38;5;34m8,256\u001b[0m │\n",
       "├──────────────────────────────────────┼─────────────────────────────┼─────────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                      │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)                   │              \u001b[38;5;34m65\u001b[0m │\n",
       "└──────────────────────────────────────┴─────────────────────────────┴─────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,178,177</span> (42.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m11,178,177\u001b[0m (42.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">11,177,729</span> (42.64 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m11,177,729\u001b[0m (42.64 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">448</span> (1.75 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m448\u001b[0m (1.75 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "\n",
    "# Define an improved CNN model\n",
    "def build_improved_model(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    \n",
    "    model.add(Conv2D(32, (3, 3), activation='relu', input_shape=input_shape))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(MaxPooling2D((2, 2)))\n",
    "    \n",
    "    model.add(Flatten())\n",
    "    model.add(Dense(128, activation='relu'))\n",
    "    model.add(Dropout(0.5))  # Dropout for regularization\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    \n",
    "    model.add(Dense(1, activation='linear'))  # Regression output\n",
    "    \n",
    "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae'])\n",
    "    return model\n",
    "\n",
    "# Build and summarize the improved model\n",
    "input_shape = (224, 224, 3)\n",
    "improved_model = build_improved_model(input_shape)\n",
    "improved_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4725f63-165a-4822-b0d2-91c038cf173a",
   "metadata": {},
   "source": [
    "**Filter Invalid Rows**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a498f8d7-ce14-4995-a20c-9cb397f6675f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize a new list for images and a corresponding list for valid values\n",
    "valid_image_data = []\n",
    "valid_values = []\n",
    "\n",
    "# Preprocess all images and keep track of valid samples\n",
    "for i in range(len(df)):\n",
    "    image_path = os.path.join(IMAGE_DIR, f'image_{i}.jpg')\n",
    "    image = preprocess_image(image_path)\n",
    "    \n",
    "    # Only keep images that are valid (non-zero arrays indicate valid images)\n",
    "    if np.any(image):\n",
    "        valid_image_data.append(image)\n",
    "        valid_values.append(df['value'].iloc[i])\n",
    "\n",
    "# Convert to numpy arrays\n",
    "image_data = np.array(valid_image_data)\n",
    "values = np.array(valid_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55bad28c-d1ca-498a-bc11-dadf1575e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 2s/step - loss: 273807.0938 - mae: 242.9842 - val_loss: 100366.2031 - val_mae: 162.3305\n",
      "Epoch 2/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 2s/step - loss: 169651.4531 - mae: 231.8053 - val_loss: 99707.8984 - val_mae: 160.6980\n",
      "Epoch 3/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 248990.6875 - mae: 237.5075 - val_loss: 99956.7031 - val_mae: 161.3149\n",
      "Epoch 4/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 125841.4688 - mae: 200.0061 - val_loss: 95726.5000 - val_mae: 152.8080\n",
      "Epoch 5/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 122333.8672 - mae: 175.6083 - val_loss: 91282.2891 - val_mae: 148.1165\n",
      "Epoch 6/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 80639.7812 - mae: 149.0043 - val_loss: 89384.3047 - val_mae: 147.7918\n",
      "Epoch 7/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 51188.4258 - mae: 134.7354 - val_loss: 86428.6719 - val_mae: 147.6526\n",
      "Epoch 8/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 73295.1406 - mae: 138.0921 - val_loss: 84453.2500 - val_mae: 147.4691\n",
      "Epoch 9/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 45885.1953 - mae: 124.6499 - val_loss: 83674.7500 - val_mae: 147.3767\n",
      "Epoch 10/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 21255.0215 - mae: 96.1920 - val_loss: 83423.6484 - val_mae: 147.4361\n",
      "Epoch 11/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 53586.3867 - mae: 124.0053 - val_loss: 81253.6250 - val_mae: 147.5978\n",
      "Epoch 12/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 104478.7188 - mae: 159.5045 - val_loss: 79411.9688 - val_mae: 147.4735\n",
      "Epoch 13/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 43733.9883 - mae: 107.6247 - val_loss: 77592.7656 - val_mae: 147.1828\n",
      "Epoch 14/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 21935.6816 - mae: 98.8542 - val_loss: 77139.0938 - val_mae: 147.4958\n",
      "Epoch 15/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 62415.0000 - mae: 104.5125 - val_loss: 75181.5781 - val_mae: 149.1354\n",
      "Epoch 16/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 16914.6641 - mae: 86.7265 - val_loss: 76007.8438 - val_mae: 149.2068\n",
      "Epoch 17/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 25795.0234 - mae: 85.5823 - val_loss: 75544.6406 - val_mae: 150.0912\n",
      "Epoch 18/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 26511.7363 - mae: 83.6958 - val_loss: 73577.9688 - val_mae: 153.2533\n",
      "Epoch 19/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 22666.6641 - mae: 94.3380 - val_loss: 73150.2812 - val_mae: 153.0276\n",
      "Epoch 20/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 69576.5703 - mae: 97.7131 - val_loss: 74984.4141 - val_mae: 150.2007\n",
      "Epoch 21/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 10564.9512 - mae: 67.3210 - val_loss: 77049.0469 - val_mae: 147.3966\n",
      "Epoch 22/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 22096.5410 - mae: 74.4387 - val_loss: 75754.5469 - val_mae: 147.8606\n",
      "Epoch 23/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 42625.7617 - mae: 86.3869 - val_loss: 74546.0156 - val_mae: 151.6152\n",
      "Epoch 24/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 92911.5312 - mae: 98.4111 - val_loss: 75138.0859 - val_mae: 155.9469\n",
      "Epoch 25/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 22611.6426 - mae: 84.6113 - val_loss: 78133.0312 - val_mae: 155.2891\n",
      "Epoch 26/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 65252.6328 - mae: 88.7231 - val_loss: 77865.3359 - val_mae: 156.6504\n",
      "Epoch 27/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 56415.4414 - mae: 98.5385 - val_loss: 73869.7266 - val_mae: 164.4373\n",
      "Epoch 28/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 30749.9004 - mae: 81.2524 - val_loss: 72560.0391 - val_mae: 167.6875\n",
      "Epoch 29/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 71090.3047 - mae: 102.0220 - val_loss: 74053.6406 - val_mae: 166.8826\n",
      "Epoch 30/30\n",
      "\u001b[1m4/4\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 2s/step - loss: 28110.9492 - mae: 85.3517 - val_loss: 74388.7578 - val_mae: 170.2437\n",
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 261ms/step - loss: 74388.7578 - mae: 170.2437\n",
      "Validation MAE: 170.24371337890625\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(image_data, df['value'], test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the improved model\n",
    "history = improved_model.fit(X_train, y_train, epochs=30, validation_data=(X_val, y_val), batch_size=32)\n",
    "\n",
    "# Evaluate the model on validation data\n",
    "val_loss, val_mae = improved_model.evaluate(X_val, y_val)\n",
    "print(f\"Validation MAE: {val_mae}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9a505d72-e424-4e4a-a8f2-c60b868dfad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 387ms/step\n",
      "[[110.260155]\n",
      " [242.92664 ]\n",
      " [ 90.34032 ]\n",
      " [ 93.6224  ]\n",
      " [405.28537 ]]\n"
     ]
    }
   ],
   "source": [
    "# testing\n",
    "predictions = improved_model.predict(X_val)\n",
    "\n",
    "# Display some results\n",
    "print(predictions[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf6f18e7-e37a-49d9-8b25-a1b2e96c1311",
   "metadata": {},
   "source": [
    "**Formating predictions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "fae5e893-4a07-4a70-a2fc-f2307745ea1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>500.000</td>\n",
       "      <td>gram</td>\n",
       "      <td>500.00 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "      <td>1.000</td>\n",
       "      <td>cup</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>0.709</td>\n",
       "      <td>gram</td>\n",
       "      <td>0.71 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>0.709</td>\n",
       "      <td>gram</td>\n",
       "      <td>0.71 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "      <td>1400.000</td>\n",
       "      <td>milligram</td>\n",
       "      <td>1400.00 gram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n",
       "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
       "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
       "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
       "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
       "\n",
       "     entity_value     value       unit    prediction  \n",
       "0      500.0 gram   500.000       gram   500.00 gram  \n",
       "1         1.0 cup     1.000        cup         1.00   \n",
       "2      0.709 gram     0.709       gram     0.71 gram  \n",
       "3      0.709 gram     0.709       gram     0.71 gram  \n",
       "4  1400 milligram  1400.000  milligram  1400.00 gram  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Formating predictions\n",
    "def format_prediction(value, entity_name):\n",
    "    # Placeholder logic for units based on entity_name\n",
    "    if entity_name in ['width', 'height', 'depth']:\n",
    "        unit = 'inch'\n",
    "    elif entity_name == 'item_weight':\n",
    "        unit = 'gram'\n",
    "    else:\n",
    "        unit = ''\n",
    "    return f\"{value:.2f} {unit}\"\n",
    "\n",
    "df['prediction'] = df.apply(lambda row: format_prediction(row['value'], row['entity_name']), axis=1)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "76498c4a-8b3c-4556-a026-4e9f85cc3a25",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_link</th>\n",
       "      <th>group_id</th>\n",
       "      <th>entity_name</th>\n",
       "      <th>entity_value</th>\n",
       "      <th>value</th>\n",
       "      <th>unit</th>\n",
       "      <th>prediction</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61I9XdN6OF...</td>\n",
       "      <td>748919</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>500.0 gram</td>\n",
       "      <td>500.000</td>\n",
       "      <td>gram</td>\n",
       "      <td>500.00 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://m.media-amazon.com/images/I/71gSRbyXmo...</td>\n",
       "      <td>916768</td>\n",
       "      <td>item_volume</td>\n",
       "      <td>1.0 cup</td>\n",
       "      <td>1.000</td>\n",
       "      <td>cup</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://m.media-amazon.com/images/I/61BZ4zrjZX...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>0.709</td>\n",
       "      <td>gram</td>\n",
       "      <td>0.71 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://m.media-amazon.com/images/I/612mrlqiI4...</td>\n",
       "      <td>459516</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>0.709 gram</td>\n",
       "      <td>0.709</td>\n",
       "      <td>gram</td>\n",
       "      <td>0.71 gram</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://m.media-amazon.com/images/I/617Tl40LOX...</td>\n",
       "      <td>731432</td>\n",
       "      <td>item_weight</td>\n",
       "      <td>1400 milligram</td>\n",
       "      <td>1400.000</td>\n",
       "      <td>milligram</td>\n",
       "      <td>1400.00 gram</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          image_link  group_id  entity_name  \\\n",
       "0  https://m.media-amazon.com/images/I/61I9XdN6OF...    748919  item_weight   \n",
       "1  https://m.media-amazon.com/images/I/71gSRbyXmo...    916768  item_volume   \n",
       "2  https://m.media-amazon.com/images/I/61BZ4zrjZX...    459516  item_weight   \n",
       "3  https://m.media-amazon.com/images/I/612mrlqiI4...    459516  item_weight   \n",
       "4  https://m.media-amazon.com/images/I/617Tl40LOX...    731432  item_weight   \n",
       "\n",
       "     entity_value     value       unit    prediction  \n",
       "0      500.0 gram   500.000       gram   500.00 gram  \n",
       "1         1.0 cup     1.000        cup         1.00   \n",
       "2      0.709 gram     0.709       gram     0.71 gram  \n",
       "3      0.709 gram     0.709       gram     0.71 gram  \n",
       "4  1400 milligram  1400.000  milligram  1400.00 gram  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rename( columns={'Unnamed: 0':'index'}, inplace=True )\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e811567b-e366-4c5c-a10c-f27c8a55d819",
   "metadata": {},
   "source": [
    "**Make prediction from test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c879d4fb-c9a7-48f0-948e-4a575bf3df84",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_DIR = \"img/test\"\n",
    "\n",
    "test = pd.read_csv(\"dataset/test.csv\")\n",
    "test = test.head(30)\n",
    "\n",
    "def download_and_process(df, IMG_DIR):\n",
    "    if not os.path.exists(IMG_DIR):\n",
    "        os.makedirs(IMG_DIR)\n",
    "    image_data = []\n",
    "    for i, row in df.iterrows():\n",
    "        image_url = row['image_link']\n",
    "        image_path = os.path.join(IMG_DIR, f'image_{i}.jpg')\n",
    "        download_image(image_url, image_path)\n",
    "        image = preprocess_image(image_path)\n",
    "        image_data.append(image)\n",
    "\n",
    "    return image_data\n",
    "\n",
    "data = download_and_process(test, IMAGE_DIR)\n",
    "\n",
    "# convert to numpy array\n",
    "data = np.array(data)\n",
    "\n",
    "prediction = improved_model.predict(data)\n",
    "\n",
    "test['prediction'] = prediction\n",
    "test['prediction'] = test.apply(lambda row: format_prediction(row['prediction'], row['entity_name']), axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3195063-bbf9-4094-a7f6-314a6af4d980",
   "metadata": {},
   "source": [
    "**Export test output file**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49925f76-eb06-4226-841f-af085cf78dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_filename = 'dataset/test2_out.csv'\n",
    "test[['index', 'prediction']].to_csv(output_filename, index=False)\n",
    "print(f\"Predictions saved to {output_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4662f0ce-78de-4613-8eb9-a361d5b49619",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
